<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chao Huang</title>
  
  <meta name="author" content="Chao Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/website_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td halign="center">
          <p align="center">
              <font size="6">Chao Huang</font>
          </p>
      </td>
    </tr>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <!-- <p style="text-align:center">
                <name>Chao Huang</name>
              </p> -->
              <p>
                I am a second-year PhD student in the Department of Computer Science at the University of Rochester, advised by <a href="https://www.cs.rochester.edu/~cxu22/">Prof. Chenliang Xu</a>. Previously, I spent one wonderful year as a research assistant at the Chinese University of Hong Kong, working with <a href="http://www.cse.cuhk.edu.hk/~cwfu/">Prof. Chi-Wing Fu</a>  on 3D vision. I received my B.Eng. from ESE Department, Nanjing University in 2019. In my undergrad, I worked with <a href="https://scholar.google.com.sg/citations?hl=en&user=78KxtRMAAAAJ">Prof. Zhan Ma</a> on image compression.
                <br>
                <br>
                I am broadly interested in developing machine learning models to understand how human perceive the real (3D) scenes from multi-modal inputs and utilize the perception for action. Specifically, I am working on audio-visual scene understanding, egocentric videos and 3D vision.
              </p>
              <p style="text-align:center">
                <a href="mailto:chuang65@cs.rochester.edu">Email</a> &nbsp/&nbsp
                <a href="data/Chao_Huang_s_CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?user=5yYP5RIAAAAJ&hl=en">Google Scholar</a> 
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <!-- <a href="https://github.com/jonbarron/">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/avatar.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/avatar.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ego_av_loc.png" alt="ego_av_loc" width="210" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle>Egocentric Audio-Visual Object
                  Localization</papertitle>
              <br>
              <strong>Chao Huang</strong>, <a href="http://www.yapengtian.com/">Yapeng Tian</a>, <a href="https://anuragkr90.github.io/">Anurag Kumar</a>, <a href="https://www.cs.rochester.edu/~cxu22/">Chenliang Xu</a>
              <br>
              <em>In Submission</em>, 2023
              <p>We explore the problem of sound source visual localization in egocentric videos, propose a new localization method and establish a benchmark for evaluation.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/av_nerf.png" alt="av_nerf" width="210" height="120">
            </td>
            <td width="75%" valign="middle">
                <papertitle>AV-NeRF: Learning Neural Fields for Real-World Audio-Visual Scene Synthesis</papertitle>
              <br>
              <a href="https://liangsusan-git.github.io/">Susan Liang</a>, <strong>Chao Huang</strong>, <a href="http://www.yapengtian.com/">Yapeng Tian</a>, <a href="https://anuragkr90.github.io/">Anurag Kumar</a>, <a href="https://www.cs.rochester.edu/~cxu22/">Chenliang Xu</a>
              <br>
              <em>In Submission</em>, 2023
              <p>We propose a novel method of synthesizing real-world audio-visual scenes at novel positions and directions.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/point_denoise.png" alt="point_denoise" width="210" height="120">
            </td>
            <td width="75%" valign="middle"><a href="https://arxiv.org/pdf/2003.06631"><papertitle>Non-Local Part-Aware Point Cloud Denoising</papertitle></a>
                
              <br>
              <strong>Chao Huang*</strong>, <a href="https://liruihui.github.io/">Ruihui Li*</a>, <a href="https://nini-lxz.github.io/">Xianzhi Li</a>, <a href="https://www.cse.cuhk.edu.hk/~cwfu/">Chi-Wing Fu</a>
              <br>
              <em>Tech Report</em>, 2020
              <p>A non-local attention based method for point cloud denoising in both synthetic and real scenes.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/extreme_compression.png" alt="extreme_compression" width="210" height="120">
            </td>
            <td width="75%" valign="middle"><a href="https://arxiv.org/pdf/1904.03851.pdf"><papertitle>Extreme Image Compression via Multiscale Autoencoders With Generative Adversarial Optimization</papertitle></a>
                
              <br>
              <strong>Chao Huang</strong>, <a href="https://scholar.google.com/citations?user=nYENH40AAAAJ&hl=zh-CN">Haojie Liu</a>, <a href="https://scholar.google.com/citations?user=HfBUtiIAAAAJ&hl=zh-CN">Tong Chen</a>, <a href="https://www.researchgate.net/profile/Qiu-Shen-3">Qiu Shen</a>, <a href="https://vision.nju.edu.cn/fc/d3/c29470a457939/page.htm">Zhan Ma</a>
              <br>
              <em>IEEE Visual Communications and Image Processing (VCIP)</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <p>An image compression system under extreme condition, <em>e.g.,</em> < 0.05 bits per pixel (bpp). </p>
            </td>
          </tr>

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td tyle="padding:20px;width:25%;vertical-align:middle"><img src="images/uofr-logo-shield.png" width="120" ></td>
            <td width="75%" valign="center">
              <strong>University of Rochester </strong>, NY, USA
              <br>
              Ph.D. in Computer Science
              <br>
              Jan. 2021 - Present
              <br> 
              Advisor: <a href="https://www.cs.rochester.edu/~cxu22/p/index.html">Chenliang Xu</a>
            </td>
          </tr>
          <tr>
            <td tyle="padding:20px;width:25%;vertical-align:middle"><img src="images/NJU_logo.jpg"  width="120"></td>
            <td width="75%" valign="center">
              <strong>Nanjing University </strong>, Nanjing, China
              <br>
              B.Eng in Electronic Science and Engineering
              <br>
              Sept. 2015 - Jun. 2019
            </td>
          </tr>
        </tbody></table>
        
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td tyle="padding:20px;width:25%;vertical-align:middle"><img src="images/CUHK_logo.png" width="120" ></td>
            <td width="75%" valign="center">
              <strong>The Chinese University of Hong Kong </strong>, Shatin, Hong Kong
              <br>
              Research Assistant
              <br>
              Jul. 2019 - Dec. 2020
              <br> 
              Advisor: <a href="http://www.cse.cuhk.edu.hk/~cwfu/">Chi-Wing Fu</a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                The template is based on <a href="http://jonbarron.info/">Jon Barron</a>'s website.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
